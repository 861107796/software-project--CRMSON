# ðŸ¤– AI Code Review Summary
## Code Reviewï¼š Summarized_narritive.ipynb
**Authorï¼š** Junbo Liang

**Review Timeï¼š** 2025-04-16 

**Code Descriptionï¼š**

Included the code for narritive summarization and labels distribution. And the data after pre-processed.


**AI Code Review summaryï¼š**

1. **Enhance Documentation:**
   - Add comments explaining the purpose of the JSON structure and its intended use.
   - Provide meaningful names for the elements, especially if more complex data is added in the future.

2. **Populate Data:**
   - Consider populating the "cells" array with relevant data to avoid the appearance of dead code and to provide context for its intended use.

3. **User Input Handling:**
   - If this JSON structure is part of a larger application, implement user input handling and validation to ensure robustness.

4. **Consider Functionality:**
   - If this JSON structure is meant to represent a notebook or data table, ensure that the code that generates or manipulates this structure is included for a comprehensive review.

**Critical Thinkingï¼š**

| Suggestion number | Whether to adopt | Thoughts and Reasons |
|----------|----------|-------------|
| 1 Enhance Documentation | Not Adopted | JSON is the standard return structure of LLM. Its field naming is not controlled by us. The comments and semantic interpretation are explained in the project documentation. |
| 2 Populate Data | Not Adopted | Currently only some of these fields are used |
| 3 User Input Handling | Not Adopted |JSON is part of the LLM interface response, validation responsibility is not inside this structure |
| 4 Consider Functionality |  Not Adopted |  This JSON is just the result returned by LLM, not the object generated by our project code. |


**Final Modificationï¼š**

- we think this json is the return type of LLM, we don't really need to use all that it included, just took the filed which is the answer part is enough.



## Code Reviewï¼š data_split.ipynb
**Authorï¼š** Hongkun Zhang

**Review Timeï¼š** 2025-04-19

**Code Descriptionï¼š**

Added a new Jupyter Notebook `data_split.ipynb` that processes the dataset by extracting all unique labels from the `assigned_labels` column and creates individual CSV files for each label. 

For each label:
- The notebook filters all rows containing that label
- Renames the `assigned_labels` column to `label`
- Replaces its content with the current label only
- Retains all other columns from the original dataset

The resulting per-label datasets are saved in the `docs/label_datasets/` directory to support downstream analysis, model training, and documentation needs.

**AI Code Review summaryï¼š**

1. **Add Inline Comments**: Include comments in the code to explain the logic and purpose of each major step, enhancing readability.
2. **Fix Indentation**: Correct the indentation within the `for` loop to maintain consistency and readability.
3. **Input Validation**: Implement checks to ensure that the input CSV file exists and contains the necessary columns before processing.
4. **Refactor Label Renaming**: Consider creating a function for the label renaming logic to promote code reuse and clarity.
5. **Consider Performance**: If the dataset is large, evaluate the performance of the filtering logic and consider optimizing it if necessary.

**Critical Thinkingï¼š**

| Suggestion number | Whether to adopt | Thoughts and Reasons |
|----------|----------|-------------|
| 1 Add Inline Comments | Adopted | The comments do make the code easier to read, and the variable naming has also been adjusted |
| 2 Fix Indentation | Adopted | Fixed indentation issues in `for` loops to improve code consistency and readability |
| 3 Input Validation | Not Adopted | Before using the code each time, the file existence and format are confirmed to be correct. |
| 4 Refactor Label Renaming |  Not Adopted |  The label renaming logic structure is simple and is only used once. Encapsulating it as a function will increase the jump and complexity. |
| 5 Consider Performance | Not Adopted | The size of the data set is limited at the current stage, and filtering performance has not yet become a bottleneck, so there is no need for optimization. |

**Final Modificationï¼š**
 
- Added step-by-step comments to illustrate the logic
- Fixed indentation within the `for` loop


## Code Reviewï¼šdialogue_specific.ipynb & role_split_clean.ipynb
**Authorï¼š** Hongkun Zhang

**Review Timeï¼š** 2025-04-23

**Code Descriptionï¼š**

This PR introduces a preprocessing script that generates two new datasets from the existing CSV files in the `label_datasets/` directory.

For each input CSV:
- One version **preserves the `label` column**, and the other does not
- Both retain only the following columns: `ACN`, `objective_summary`, `label` (optional), `Party1_Role`, and `Party2_Role`
- The column `Person 1.8_Communication Breakdown` is removed
- Two new columns `Party1_Role` and `Party2_Role` are extracted and inserted immediately after the `ACN` column, based on the original breakdown text

The resulting datasets are stored in the `label_datasets_with_roles/` directory.

**AI Code Review summaryï¼š**

1. **Enhance Documentation**: Add comments explaining the purpose of blocks of code and consider renaming variables and functions for clarity.
2. **Refactor Code**: Remove duplicate logic for creating `new_order` and simplify long lines for readability.
3. **Error Handling**: Improve error handling in `split_parties` and add input validation for the CSV files.
4. **Optimize Memory Usage**: Consider processing large files in chunks to avoid memory overload.
5. **Parameterization**: Use constants or configuration files for column names and other hardcoded values to improve flexibility.

**Critical Thinkingï¼š**

| Suggestion number | Whether to adopt | Thoughts and Reasons |
|----------|----------|-------------|
| 1 Enhance Documentation| Adopted | The comments do make the code easier to read, and the variable naming has also been adjusted |
| 2 Refactor Code | Not Adopted | `new_order` is repeated, but the logic is clear and it is only used twice. Refactoring may reduce readability. |
| 3 Error Handling | Partially Adopted | Input validation and basic error prompts have been added, but detailed exception types have not yet been processed |
| 4 Optimize Memory Usage |  Not Adopted | The current data volume is controllable and block processing is not used for the time being, but it has been marked as a direction for subsequent optimization |
| 5 Parameterization | Not Adopted | Data preprocessing does not require the introduction of additional configuration files to increase complexity |

**Final Modificationï¼š**

- Added comments to explain code module logic and goals
- `split_parties` function uses try-except to simplify exception prompts

## Code Reviewï¼šmodel_fine_tuning_1.ipynb
**Authorï¼š** Yutao Zhou

**Review Timeï¼š** 2025-05-28

**Code Descriptionï¼š**

This PR  included the code for training dataset generation and model fine-tuning.


**AI Code Review summaryï¼š**

1. **Improve Comments**:  Enhance the clarity and conciseness of comments, and add inline comments where necessary.
2. **Break Long Lines**:  Refactor long lines (like multi-line strings) for better readability.
3. **Refactor Repeated Logic**:  Identify repeated logic and encapsulate it in functions to promote DRY (Don't Repeat Yourself) principles.
4. **Input Validation**:  Implement input validation in the `multi_turn_chat` function and for file paths in the `convert_jsonl` function.
5. **Exception Handling**:  Refine exception handling to catch specific exceptions and provide more informative error messages.
6. **Review Memory Usage**: Assess the use of `keep_in_memory=True` and consider alternatives if the dataset is large.
7. **Remove Unnecessary Delays**: Evaluate the necessity of `time.sleep(0.5)` and remove it if it does not serve a purpose.

**Critical Thinkingï¼š**

| Suggestion number | Whether to adopt | Thoughts and Reasons |
|----------|----------|-------------|
| 1 Improve Comments| Adopted | We have enhanced the clarity and conciseness of comments throughout the codebase. |
| 2 Break Long Lines | Not Adopted | While some lines exceed conventional length limits, they remain readable and contextually clear.  |
| 3 Refactor Repeated Logic | Not Adopted | In this script, there is no repeated logic. |
| 4 Input Validation |  Adopted | Input validation has been implemented in the `multi_turn_chat` function and for file paths in the `convert_json` function to ensure robustness and prevent unexpected behavior due to invalid inputs. |
| 5 Exception Handling | Not Adopted |The current exception handling is sufficient for this sprint's scope.  |
| 6 Review Memory Usage | Not Adopted |Keep in memory is necessary, otherwise it took longer time to run.   |
| 7 Remove Unnecessary Delays| Not Adopted |time.sleep() is necessary, otherwise the model server might refuse the request.  |
**Final Modificationï¼š**

- Inline comments were added
- Input validation has been implemented in the `multi_turn_chat` function and for file paths in the `convert_json` function

## Code Reviewï¼šdemo.py
**Authorï¼š** Yifeng Su

**Review Timeï¼š** 2025-05-29

**Code Descriptionï¼š**

This PR  included the script for frontend design (Gradio).


**AI Code Review summaryï¼š**

1. **Security of Secrets**:  Ensure `api-key.env` is excluded from version control using `.gitignore`. Add existence and fallback checks for `DIFY_API_KEY` to avoid runtime failure when the file is missing or the variable is not set.
2. **Avoid Magic Numbers**:  Replace hardcoded `time.sleep(0.01)` with a named constant like `STREAM_DELAY = 0.01` for better readability and configurability.
3. **Modularization**:  Separate UI logic and backend logic into different modules (e.g., `ui.py`, `logic.py`) to improve code organization and testability.
4. **Add Logging**:  Replace` print()` statements with the Python `logging` module to support logging levels and better error tracking during deployment.
5. **Exception Handling**:  Refine exception handling by catching more specific exceptions (e.g., requests.exceptions.RequestException) instead of a generic Exception, and provide clearer error feedback in the UI.


**Critical Thinkingï¼š**

| Suggestion number | Whether to adopt | Thoughts and Reasons |
|----------|----------|-------------|
| 1 Security of Secrets| Not Adopted | The project is under local development and version control is restricted. For now, managing `api-key.env` manually is sufficient.|
| 2 Avoid Magic Numbers | Not Adopted | `time.sleep(0.01)` is clear and only used once. Extracting it into a constant would reduce code conciseness without tangible benefits.  |
| 3 Modularization | Not Adopted | Given the small size of the script, separating it into multiple files would introduce unnecessary complexity |
| 4 Add Logging |  Not Adopted | `print()` is sufficient for debugging during development.|
| 5 Exception Handling | Adopted |Refine exception handling by catching more specific exceptions |

**Final Modificationï¼š**

- Refine exception handling by catching more specific exceptions 
